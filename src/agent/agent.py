"""LangChain agent orchestrator with Claude."""
import os
from typing import Dict, Any

# === Agent Execution Context ===
# Thread-safe execution context (replaces global mutable dict)
from src.agent.execution_context import (
    execution_context,  # Backward compatibility proxy
    execution_context_scope,
    get_execution_context
)

# === LangSmith Integration ===
# CRITICAL: Set environment variables BEFORE importing LangChain modules
# LangChain checks these during import, so they must be set first
from src.config import settings
from src.utils.logger import log

if settings.langchain_api_key:
    os.environ["LANGCHAIN_TRACING_V2"] = "true" if settings.langchain_tracing_v2 else "false"
    os.environ["LANGCHAIN_API_KEY"] = settings.langchain_api_key
    os.environ["LANGCHAIN_PROJECT"] = settings.langchain_project
    os.environ["LANGCHAIN_ENDPOINT"] = settings.langchain_endpoint
    log.info(f"LangSmith tracing enabled for project: {settings.langchain_project}")
else:
    log.warning("LangSmith API key not configured - tracing disabled")

# Import LangChain AFTER setting environment variables
from langchain_anthropic import ChatAnthropic
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from src.agent.tools import all_tools


# System prompt for the agent (in French since all internal logic is in French)
SYSTEM_PROMPT = """Tu es Lumiera, l'assistant virtuel pour les sous-traitants du BTP.

# IDENTIT√â
- Nom: Lumiera
- R√¥le: Aider les sous-traitants √† g√©rer leurs chantiers via WhatsApp
- Ton: Professionnel, chaleureux, efficace

# CAPACIT√âS
1. Lister les chantiers actifs - Voir tous les projets en cours
2. Consulter les t√¢ches - D√©tails des t√¢ches par projet
3. Signaler des incidents - Avec photos et description
4. Mettre √† jour la progression - Avancement des t√¢ches
5. Parler avec un humain - Redirection vers l'√©quipe administrative

# R√àGLES CRITIQUES (S√âCURIT√â)

## ‚ö†Ô∏è PROTECTION DES DONN√âES
1. ‚ùå L'utilisateur NE PEUT VOIR QUE SES PROPRES DONN√âES
2. ‚ùå JAMAIS afficher des donn√©es d'autres utilisateurs
3. ‚úÖ TOUJOURS filtrer par user_id dans TOUTES les requ√™tes d'outils
4. ‚úÖ V√©rifier que project_id/task_id appartient √† l'utilisateur avant d'afficher

## üìã FORMAT DE R√âPONSE
1. ‚ùå JAMAIS afficher les IDs techniques (proj_123, task_456, uuid...)
2. ‚úÖ Utiliser uniquement les NOMS lisibles (ex: "R√©novation Bureau")
3. ‚úÖ Listes num√©rot√©es pour menu/options (format: "1. Titre - Description")
4. ‚úÖ Emoji pour clart√©: üëã ‚úÖ ‚ùå üì∏ üìù üèóÔ∏è
5. ‚úÖ R√©ponses courtes et claires (WhatsApp = mobile)
6. ‚úÖ Utiliser UN SEUL asterisque pour le gras (*texte*) - JAMAIS deux (**texte**)
7. ‚úÖ Les listes num√©rot√©es deviennent automatiquement des boutons cliquables sur WhatsApp

## üõ†Ô∏è UTILISATION DES OUTILS
1. ‚úÖ TOUJOURS utiliser les outils fournis
2. ‚ùå JAMAIS inventer de donn√©es
3. ‚úÖ Si incertain, demander pr√©cisions
4. ‚úÖ Si hors de tes capacit√©s, proposer "parler avec un humain"
5. ‚úÖ Pour incidents: au moins 1 image + description obligatoires

# EXEMPLES (SANS IDs TECHNIQUES)

Utilisateur: "Bonjour"
Assistant: "Bonjour! üëã Comment puis-je vous aider aujourd'hui?

1. üèóÔ∏è Voir mes chantiers actifs
2. üìã Consulter mes t√¢ches
3. üö® Signaler un incident
4. ‚úÖ Mettre √† jour ma progression
5. üó£Ô∏è Parler avec l'√©quipe

Que souhaitez-vous faire?"

Utilisateur: "Quels sont mes chantiers?"
Assistant: "Vous avez 3 chantiers actifs:

1. üèóÔ∏è R√©novation Bureau - En cours
2. üè† Construction Maison - Planifi√©
3. üî® Extension Garage - En cours

Lequel souhaitez-vous consulter?"

Utilisateur: "Je veux signaler un probl√®me"
Assistant: "Je vais vous aider √† signaler un incident.

J'ai besoin de:
1. üì∏ Une photo du probl√®me
2. üìù Une description
3. üèóÔ∏è Le chantier concern√©

Commencez par m'envoyer une photo."

Utilisateur: "Je suis bloqu√©"
Assistant: "Je comprends. Souhaitez-vous parler avec un membre de l'√©quipe administrative?

Je peux vous mettre en contact avec quelqu'un qui pourra mieux vous aider."

# SI TU NE PEUX PAS AIDER
Proposer: "Souhaitez-vous parler avec un membre de l'√©quipe? Je peux vous mettre en contact."

# üß† M√âMORISATION ET PERSONNALISATION
1. ‚úÖ TOUJOURS m√©moriser les informations importantes avec remember_user_context_tool
2. ‚úÖ M√©moriser quand l'utilisateur mentionne:
   - Son r√¥le/m√©tier (ex: "Je suis √©lectricien" ‚Üí role: electricien)
   - Ses pr√©f√©rences (ex: "Appelez-moi le matin" ‚Üí preferred_contact_time: morning)
   - Le projet en cours de discussion (ex: "Sur le chantier R√©novation Bureau" ‚Üí current_project_name: R√©novation Bureau)
   - Des faits utiles (taille √©quipe, outils pr√©f√©r√©s, probl√®mes fr√©quents)
3. ‚úÖ Utiliser le contexte existant pour personnaliser les r√©ponses
4. ‚ö†Ô∏è Ne PAS redemander des infos d√©j√† m√©moris√©es

Types de contexte √† m√©moriser:
- 'fact': Faits g√©n√©raux (r√¥le, exp√©rience, sp√©cialit√©s)
- 'preference': Pr√©f√©rences utilisateur (horaires, communication)
- 'state': √âtat temporaire (projet actuel, t√¢che en cours)
- 'entity': Entit√©s nomm√©es (projet favori, lieu fr√©quent)

# RAPPELS FINAUX
- Tu op√®res en fran√ßais en interne (messages d√©j√† traduits)
- Ta r√©ponse sera traduite dans la langue de l'utilisateur
- JAMAIS d'IDs techniques dans les r√©ponses
- Toujours filtrer par user_id pour la s√©curit√©"""


def create_agent() -> AgentExecutor:
    """Create and configure the LangChain agent with Claude."""

    # Initialize Claude model
    llm = ChatAnthropic(
        model=settings.anthropic_model,
        api_key=settings.anthropic_api_key,
        temperature=settings.anthropic_temperature,
        max_tokens=settings.anthropic_max_tokens,
    )

    # Create prompt template
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # Create agent with tool calling
    agent = create_tool_calling_agent(llm, all_tools, prompt)

    # Create agent executor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=all_tools,
        verbose=settings.debug,
        handle_parsing_errors=True,
        max_iterations=5,
    )

    log.info("Agent created successfully")
    return agent_executor


class LumieraAgent:
    """Main agent class for handling user requests."""

    def __init__(self):
        """Initialize the Lumiera agent."""
        self.agent_executor = create_agent()
        log.info("Lumiera Agent initialized")

    async def process_message(
        self,
        user_id: str,
        phone_number: str,
        language: str,
        message_text: str,
        chat_history: list = None,
        user_name: str = "",
        user_context: str = "",
    ) -> str:
        """Process a user message and return a response.

        Args:
            user_id: The user's ID
            phone_number: The user's WhatsApp phone number
            language: The user's preferred language
            message_text: The message text (already translated to French)
            chat_history: Optional chat history for context
            user_name: Official contact name from subcontractors table
            user_context: Additional user context for personalization

        Returns:
            The response text (in French, to be translated back)
        """
        # Use execution context scope for thread-safe execution tracking
        with execution_context_scope() as ctx:
            try:
                # Add user context to the message
                # NOTE: Language code is intentionally NOT included here to ensure
                # agent always responds in French (internal processing language).
                # Translation to user language happens in the pipeline after agent response.
                context_prefix = "[Contexte utilisateur]\n"
                if user_name:
                    context_prefix += f"Nom: {user_name}\n"
                # Language code removed - agent must always respond in French
                if user_context:
                    context_prefix += f"Contexte additionnel:\n{user_context}\n"
                context_prefix += "\n"

                # Prepare agent input
                agent_input = {
                    "input": f"{context_prefix}{message_text}",
                    "user_id": user_id,
                    "phone_number": phone_number,
                    "language": language,
                }

                if chat_history:
                    agent_input["chat_history"] = chat_history

                # Run agent
                result = await self.agent_executor.ainvoke(agent_input)

                # Extract output
                output = result.get("output", "D√©sol√©, je n'ai pas pu traiter votre demande.")

                # Normalize output to string (LangChain sometimes returns dict/list)
                if isinstance(output, dict):
                    # Extract 'text' field from dict: {'text': '...', 'type': 'text', 'index': 0}
                    log.warning(f"Agent returned dict output, extracting text field")
                    output = output.get('text', str(output))
                elif isinstance(output, list):
                    # List items might be dicts with 'text' field or plain strings
                    log.warning(f"Agent returned list output ({len(output)} items), extracting text")
                    extracted_items = []
                    for item in output:
                        if isinstance(item, dict):
                            # Extract 'text' field from dict item
                            extracted_items.append(item.get('text', str(item)))
                        else:
                            # Plain string or other type
                            extracted_items.append(str(item))
                    output = '\n'.join(extracted_items)
                elif not isinstance(output, str):
                    # Fallback: convert to string
                    log.warning(f"Agent returned unexpected type {type(output)}, converting to string")
                    output = str(output)

                # Get escalation flag from execution context (set by tools)
                escalation_occurred = ctx.escalation_occurred

                log.info(f"Agent processed message for user {user_id}")
                log.info(f"Escalation occurred: {escalation_occurred}")
                log.info(f"Tools called: {ctx.tools_called}")

                # Return structured data (output is guaranteed to be string now)
                return {
                    "message": output,
                    "escalation": escalation_occurred,
                    "tools_called": ctx.tools_called
                }

            except Exception as e:
                log.error(f"Error processing message: {e}")
                return {
                    "message": "D√©sol√©, une erreur s'est produite. Veuillez r√©essayer.",
                    "escalation": False,
                    "tools_called": []
                }


# Global agent instance
lumiera_agent = LumieraAgent()
