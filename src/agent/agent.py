"""LangChain agent orchestrator with Claude."""
from typing import Dict, Any
from langchain_anthropic import ChatAnthropic
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from src.agent.tools import all_tools
from src.config import settings
from src.utils.logger import log


# System prompt for the agent (in French since all internal logic is in French)
SYSTEM_PROMPT = """Tu es Lumiera, l'assistant virtuel pour les sous-traitants du BTP.

# IDENTIT√â
- Nom: Lumiera
- R√¥le: Aider les sous-traitants √† g√©rer leurs chantiers via WhatsApp
- Ton: Professionnel, chaleureux, efficace

# CAPACIT√âS
1. **Lister les chantiers actifs** - Voir tous les projets en cours
2. **Consulter les t√¢ches** - D√©tails des t√¢ches par projet
3. **Signaler des incidents** - Avec photos et description
4. **Mettre √† jour la progression** - Avancement des t√¢ches
5. **Parler avec un humain** - Redirection vers l'√©quipe administrative

# R√àGLES CRITIQUES (S√âCURIT√â)

## ‚ö†Ô∏è PROTECTION DES DONN√âES
1. ‚ùå L'utilisateur NE PEUT VOIR QUE SES PROPRES DONN√âES
2. ‚ùå JAMAIS afficher des donn√©es d'autres utilisateurs
3. ‚úÖ TOUJOURS filtrer par user_id dans TOUTES les requ√™tes d'outils
4. ‚úÖ V√©rifier que project_id/task_id appartient √† l'utilisateur avant d'afficher

## üìã FORMAT DE R√âPONSE
1. ‚ùå JAMAIS afficher les IDs techniques (proj_123, task_456, uuid...)
2. ‚úÖ Utiliser uniquement les NOMS lisibles (ex: "R√©novation Bureau")
3. ‚úÖ Listes num√©rot√©es pour plusieurs items
4. ‚úÖ Emoji pour clart√©: üëã ‚úÖ ‚ùå üì∏ üìù üèóÔ∏è
5. ‚úÖ R√©ponses courtes et claires (WhatsApp = mobile)

## üõ†Ô∏è UTILISATION DES OUTILS
1. ‚úÖ TOUJOURS utiliser les outils fournis
2. ‚ùå JAMAIS inventer de donn√©es
3. ‚úÖ Si incertain, demander pr√©cisions
4. ‚úÖ Si hors de tes capacit√©s, proposer "parler avec un humain"
5. ‚úÖ Pour incidents: au moins 1 image + description obligatoires

# EXEMPLES (SANS IDs TECHNIQUES)

**Utilisateur**: "Quels sont mes chantiers?"
**Assistant**: "Vous avez 3 chantiers actifs:

1. üèóÔ∏è **R√©novation Bureau** - En cours
2. üè† **Construction Maison** - Planifi√©
3. üî® **Extension Garage** - En cours

Lequel souhaitez-vous consulter?"

**Utilisateur**: "Je veux signaler un probl√®me"
**Assistant**: "Je vais vous aider √† signaler un incident.

J'ai besoin de:
1. üì∏ Une photo du probl√®me
2. üìù Une description
3. üèóÔ∏è Le chantier concern√©

Commencez par m'envoyer une photo."

**Utilisateur**: "Je suis bloqu√©"
**Assistant**: "Je comprends. Souhaitez-vous parler avec un membre de l'√©quipe administrative?

Je peux vous mettre en contact avec quelqu'un qui pourra mieux vous aider."

# CONTEXTE UTILISATEUR
- Nom: {user_name}
- Langue: {user_language}
- Contexte additionnel: {user_context}

# SI TU NE PEUX PAS AIDER
Proposer: "Souhaitez-vous parler avec un membre de l'√©quipe? Je peux vous mettre en contact."

# RAPPELS FINAUX
- Tu op√®res en fran√ßais en interne (messages d√©j√† traduits)
- Ta r√©ponse sera traduite dans la langue de l'utilisateur
- JAMAIS d'IDs techniques dans les r√©ponses
- Toujours filtrer par user_id pour la s√©curit√©"""


def create_agent() -> AgentExecutor:
    """Create and configure the LangChain agent with Claude."""

    # Initialize Claude model
    llm = ChatAnthropic(
        model=settings.anthropic_model,
        api_key=settings.anthropic_api_key,
        temperature=settings.anthropic_temperature,
        max_tokens=settings.anthropic_max_tokens,
    )

    # Create prompt template
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # Create agent with tool calling
    agent = create_tool_calling_agent(llm, all_tools, prompt)

    # Create agent executor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=all_tools,
        verbose=settings.debug,
        handle_parsing_errors=True,
        max_iterations=5,
    )

    log.info("Agent created successfully")
    return agent_executor


class LumieraAgent:
    """Main agent class for handling user requests."""

    def __init__(self):
        """Initialize the Lumiera agent."""
        self.agent_executor = create_agent()
        log.info("Lumiera Agent initialized")

    async def process_message(
        self,
        user_id: str,
        phone_number: str,
        language: str,
        message_text: str,
        chat_history: list = None,
        user_name: str = "",
        user_context: str = "",
    ) -> str:
        """Process a user message and return a response.

        Args:
            user_id: The user's ID
            phone_number: The user's WhatsApp phone number
            language: The user's preferred language
            message_text: The message text (already translated to French)
            chat_history: Optional chat history for context
            user_name: Official contact name from subcontractors table
            user_context: Additional user context for personalization

        Returns:
            The response text (in French, to be translated back)
        """
        try:
            # Add user context to the message
            context_prefix = "[Contexte utilisateur]\n"
            if user_name:
                context_prefix += f"Nom: {user_name}\n"
            if language:
                context_prefix += f"Langue: {language}\n"
            if user_context:
                context_prefix += f"Contexte additionnel:\n{user_context}\n"
            context_prefix += "\n"

            # Prepare agent input
            agent_input = {
                "input": f"{context_prefix}{message_text}",
                "user_id": user_id,
                "phone_number": phone_number,
                "language": language,
            }

            if chat_history:
                agent_input["chat_history"] = chat_history

            # Run agent
            result = await self.agent_executor.ainvoke(agent_input)

            # Extract output
            output = result.get("output", "D√©sol√©, je n'ai pas pu traiter votre demande.")

            log.info(f"Agent processed message for user {user_id}")
            return output

        except Exception as e:
            log.error(f"Error processing message: {e}")
            return "D√©sol√©, une erreur s'est produite. Veuillez r√©essayer."


# Global agent instance
lumiera_agent = LumieraAgent()
