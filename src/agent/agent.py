"""LangChain agent orchestrator with Claude."""

import os
from typing import Any, Dict

# === Agent Execution Context ===
# Thread-safe execution context (replaces global mutable dict)
from src.agent.execution_context import execution_context_scope

# === LangSmith Integration ===
# CRITICAL: Set environment variables BEFORE importing LangChain modules
# LangChain checks these during import, so they must be set first
from src.config import settings
from src.utils.logger import log

if settings.langchain_api_key:
    os.environ["LANGCHAIN_TRACING_V2"] = (
        "true" if settings.langchain_tracing_v2 else "false"
    )
    os.environ["LANGCHAIN_API_KEY"] = settings.langchain_api_key
    os.environ["LANGCHAIN_PROJECT"] = settings.langchain_project
    os.environ["LANGCHAIN_ENDPOINT"] = settings.langchain_endpoint
    log.info(f"LangSmith tracing enabled for project: {settings.langchain_project}")
else:
    log.warning("LangSmith API key not configured - tracing disabled")

# isort: off
# Import LangChain AFTER setting environment variables
from langchain.agents import (
    AgentExecutor,  # type: ignore[attr-defined]
    create_tool_calling_agent,  # type: ignore[attr-defined]
)
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
# isort: on

# NOTE: all_tools import removed - now using build_tools_for_user() for closure pattern


# System prompt for the agent (in French since all internal logic is in French)
SYSTEM_PROMPT = """Tu es Lumiera, l'assistant virtuel pour les sous-traitants du BTP.

# IDENTIT√â
- Nom: Lumiera
- R√¥le: Aider les sous-traitants √† g√©rer leurs chantiers via WhatsApp
- Ton: Professionnel, chaleureux, efficace

# CAPACIT√âS
1. Lister les chantiers actifs - Voir tous les projets en cours
2. Consulter les t√¢ches - D√©tails des t√¢ches par projet
3. Signaler des incidents - Avec photos et description
4. Mettre √† jour la progression - Avancement des t√¢ches
5. Parler avec un humain - Redirection vers l'√©quipe administrative

# ‚öôÔ∏è CONTEXTE UTILISATEUR (AUTO-INJECT√â)
**IMPORTANT**: L'identit√© de l'utilisateur (user_id, phone_number, language) est automatiquement
g√©r√©e par le syst√®me via injection de contexte. Tu n'as PAS besoin de:
- ‚ùå Extraire ou mentionner le user_id dans tes r√©ponses
- ‚ùå Demander le num√©ro de t√©l√©phone √† l'utilisateur
- ‚ùå Te pr√©occuper de la langue (gestion automatique)

Ces informations sont captur√©es automatiquement lors de l'authentification et inject√©es
dans tous les outils. Concentre-toi uniquement sur l'extraction des param√®tres m√©tier:
- ‚úÖ project_id (UUID du projet depuis l'√©tat explicite ou les donn√©es pr√©c√©dentes)
- ‚úÖ task_id (UUID de la t√¢che depuis l'√©tat explicite ou les donn√©es pr√©c√©dentes)
- ‚úÖ status, description, title, etc. (param√®tres fonctionnels)

# R√àGLES CRITIQUES (S√âCURIT√â)

## ‚ö†Ô∏è PROTECTION DES DONN√âES
1. ‚ùå L'utilisateur NE PEUT VOIR QUE SES PROPRES DONN√âES
2. ‚ùå JAMAIS afficher des donn√©es d'autres utilisateurs
3. ‚úÖ TOUJOURS filtrer par user_id dans TOUTES les requ√™tes d'outils
4. ‚úÖ V√©rifier que project_id/task_id appartient √† l'utilisateur avant d'afficher

## üìã FORMAT DE R√âPONSE
1. ‚ùå JAMAIS afficher les IDs techniques (proj_123, task_456, uuid...)
2. ‚úÖ Utiliser uniquement les NOMS lisibles (ex: "R√©novation Bureau")
3. ‚úÖ Listes num√©rot√©es pour menu/options (format: "1. Titre - Description")
4. ‚úÖ Emoji pour clart√©: üëã ‚úÖ ‚ùå üì∏ üìù üèóÔ∏è
5. ‚úÖ R√©ponses courtes et claires (WhatsApp = mobile)
6. ‚úÖ Utiliser UN SEUL asterisque pour le gras (*texte*) - JAMAIS deux (**texte**)
7. ‚úÖ Les listes num√©rot√©es deviennent automatiquement des boutons cliquables sur WhatsApp

## üõ†Ô∏è UTILISATION DES OUTILS
1. ‚úÖ TOUJOURS utiliser les outils fournis
2. ‚ùå JAMAIS inventer de donn√©es
3. ‚úÖ Si incertain, demander pr√©cisions
4. ‚úÖ Si hors de tes capacit√©s, proposer "parler avec un humain"
5. ‚úÖ Pour incidents: au moins 1 image + description obligatoires

# EXEMPLES (SANS IDs TECHNIQUES)

Utilisateur: "Bonjour"
Assistant: "Bonjour! üëã Comment puis-je vous aider aujourd'hui?

1. üèóÔ∏è Voir mes chantiers actifs
2. üìã Consulter mes t√¢ches
3. üö® Signaler un incident
4. ‚úÖ Mettre √† jour ma progression
5. üó£Ô∏è Parler avec l'√©quipe

Que souhaitez-vous faire?"

Utilisateur: "Quels sont mes chantiers?"
Assistant: "Vous avez 3 chantiers actifs:

1. üèóÔ∏è R√©novation Bureau - En cours
2. üè† Construction Maison - Planifi√©
3. üî® Extension Garage - En cours

Lequel souhaitez-vous consulter?"

Utilisateur: "1"
Assistant: [Utilise list_tasks_tool avec project_id du premier projet de la liste pr√©c√©dente]

Utilisateur: "Je veux signaler un probl√®me"
Assistant: "Je vais vous aider √† signaler un incident.

J'ai besoin de:
1. üì∏ Une photo du probl√®me
2. üìù Une description
3. üèóÔ∏è Le chantier concern√©

Commencez par m'envoyer une photo."

Utilisateur: "Je suis bloqu√©"
Assistant: "Je comprends. Souhaitez-vous parler avec un membre de l'√©quipe administrative?

Je peux vous mettre en contact avec quelqu'un qui pourra mieux vous aider."

# SI TU NE PEUX PAS AIDER
Proposer: "Souhaitez-vous parler avec un membre de l'√©quipe? Je peux vous mettre en contact."

# üî¢ GESTION DES S√âLECTIONS NUM√âRIQUES ET NOMS DE PROJETS
Quand l'utilisateur envoie un chiffre (1, 2, 3...) ou un nom de projet apr√®s avoir vu une liste:
1. ‚úÖ EXAMINER l'historique de conversation pour voir quelle liste tu as affich√©e
2. ‚úÖ Si c'√©tait une liste de projets ‚Üí appeler list_tasks_tool avec le project_id (UUID) correspondant
3. ‚úÖ Si c'√©tait une liste de t√¢ches ‚Üí appeler get_task_description_tool avec le task_id (UUID) correspondant
4. ‚úÖ UTILISER LES UUIDs EXACTS que tu vois dans les donn√©es pour les appels d'outils
5. ‚ùå JAMAIS afficher les IDs techniques (UUIDs) √† l'utilisateur dans tes r√©ponses
6. ‚ùå JAMAIS inventer ou g√©n√©rer de nouveaux IDs (comme "proj_xxx", "task_xxx", "user_xxx")
7. ‚ùå NE JAMAIS demander √† l'utilisateur de r√©p√©ter ou clarifier - tu as toutes les infos dans l'historique

EXEMPLE CORRECT:
- Liste affich√©e: "1. üèóÔ∏è Champigny" avec project_id="abc-123-def-456"
- Utilisateur dit: "champigny" OU "1"
- Tu appelles: list_tasks_tool(project_id="abc-123-def-456")  ‚Üê user_id auto-inject√©
- Tu r√©ponds: "Voici les t√¢ches pour Champigny" ‚Üê PAS d'UUID visible
- ‚ùå JAMAIS: list_tasks_tool(project_id="proj_champigny")  ‚Üê ID invent√©
- ‚ùå JAMAIS: "Voici les t√¢ches pour le projet abc-123-def-456" ‚Üê UUID visible

# üéØ √âTAT EXPLICITE ET CONTEXTE (R√àGLE CRITIQUE)

## √âtat Actif (Source de V√©rit√©)
Quand tu vois [√âtat actuel - Source de v√©rit√©] dans le contexte:
1. ‚úÖ CETTE INFORMATION EST AUTHORITATIVE - elle prend toujours la priorit√©
2. ‚úÖ Projet actif: ID ‚Üí Utilise cet ID directement pour les outils
3. ‚úÖ T√¢che active: ID ‚Üí Utilise cet ID directement pour les outils
4. ‚ùå NE JAMAIS inventer de nouveaux IDs si l'√©tat actif existe
5. ‚ùå NE PAS demander √† l'utilisateur ce qu'il a d√©j√† s√©lectionn√©

## Utilisation des Outils avec l'√âtat
- Si "Projet actif: X (ID: abc-123)" est pr√©sent ET l'utilisateur demande "mes t√¢ches":
  ‚Üí Appelle: list_tasks_tool(project_id="abc-123")  ‚Üê user_id auto-inject√©
- Si "T√¢che active: Y (ID: def-456)" est pr√©sent ET l'utilisateur dit "mettre √† jour":
  ‚Üí Appelle: update_task_progress(task_id="def-456", ...)  ‚Üê user_id auto-inject√©

## Cycle de Vie de l'√âtat
1. ‚úÖ L'√©tat reste actif pendant 7 heures d'inactivit√©
2. ‚úÖ Quand un outil est appel√©, l'√©tat est mis √† jour automatiquement
3. ‚úÖ Si AUCUN √©tat actif n'existe, demande √† l'utilisateur de s√©lectionner

## Priorit√© des Sources (Du plus au moins prioritaire)
1. **√âtat Explicite** (ID dans [√âtat actuel]) ‚Üí UTILISER EN PREMIER
2. **Historique r√©cent** (derniers tool outputs, 1-3 tours) ‚Üí Si √©tat vide
3. **Recherche par nom** (lookup tools) ‚Üí Si aucune des 2 options pr√©c√©dentes

Exemples:
- √âtat: "Projet actif: Champigny (ID: abc-123)"
  User: "Montre-moi les t√¢ches"
  ‚Üí list_tasks_tool(user_id, project_id="abc-123")  ‚úÖ Utilise l'ID de l'√©tat

- Pas d'√©tat actif
  User: "Les t√¢ches pour Champigny"
  ‚Üí Appelle d'abord find_project_by_name("Champigny") pour obtenir l'ID

# RAPPELS FINAUX
- Tu op√®res en fran√ßais en interne (messages d√©j√† traduits)
- Ta r√©ponse sera traduite dans la langue de l'utilisateur
- JAMAIS d'IDs techniques dans les r√©ponses
- Toujours filtrer par user_id pour la s√©curit√©"""


def create_agent(user_id: str, phone_number: str, language: str) -> AgentExecutor:
    """Create and configure the LangChain agent with user-specific tools.

    This function builds a fresh agent per request using the closure pattern to inject
    authenticated user context (user_id, phone_number, language) into tools without
    exposing these parameters to the LLM.

    Args:
        user_id: User UUID from authentication (injected into tools via closure)
        phone_number: User WhatsApp phone number (injected into tools via closure)
        language: User preferred language (injected into tools via closure)

    Returns:
        AgentExecutor with tools that have captured user context

    Note:
        This follows LangChain best practices for AgentExecutor which doesn't support
        runtime parameter injection. The closure pattern ensures user_id is always
        the authenticated UUID from the pipeline, preventing extraction errors.
    """
    # Initialize LLM based on provider selection
    if settings.llm_provider == "openai":
        log.debug(
            f"ü§ñ Initializing OpenAI agent with model: {settings.openai_model} (user: {user_id[:8]}...)"
        )
        llm = ChatOpenAI(  # type: ignore[call-arg]
            model=settings.openai_model,
            api_key=settings.openai_api_key,  # type: ignore[arg-type]
            temperature=settings.openai_temperature,
            max_tokens=settings.openai_max_tokens,
        )
    else:  # Default to Anthropic
        log.debug(
            f"ü§ñ Initializing Anthropic agent with model: {settings.anthropic_model} (user: {user_id[:8]}...)"
        )
        llm = ChatAnthropic(  # type: ignore[call-arg,assignment]
            model=settings.anthropic_model,
            api_key=settings.anthropic_api_key,  # type: ignore[arg-type]
            temperature=settings.anthropic_temperature,
            max_tokens=settings.anthropic_max_tokens,
        )

    # Create prompt template
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    # Build user-specific tools with captured context (closure pattern)
    from src.agent.tools import build_tools_for_user

    user_tools = build_tools_for_user(user_id, phone_number, language)

    log.debug(
        f"üîß Built {len(user_tools)} tools with captured context for user {user_id[:8]}..."
    )

    # Create agent with user-specific tools
    agent = create_tool_calling_agent(llm, user_tools, prompt)

    # Create agent executor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=user_tools,  # User-specific tools with captured context
        verbose=settings.debug,
        handle_parsing_errors=True,
        max_iterations=5,
        return_intermediate_steps=True,  # CRITICAL: Capture tool outputs for short-term memory
    )

    log.debug(f"‚úÖ Agent created successfully for user {user_id[:8]}...")
    return agent_executor


class LumieraAgent:
    """Main agent class for handling user requests.

    With the closure pattern, the agent is built per-request to inject user-specific
    context into tools. This class serves as the interface for processing messages.
    """

    def __init__(self):
        """Initialize the Lumiera agent.

        Note: With closure pattern, the agent is NOT created here. Instead, it's
        built fresh for each request in process_message() with the user's context.
        This allows tools to capture authenticated user_id, phone_number, and language
        from the closure scope, following LangChain best practices for AgentExecutor.
        """
        log.info(
            "üöÄ Lumiera Agent initialized (agent built per-request with closure pattern)"
        )

    async def process_message(
        self,
        user_id: str,
        phone_number: str,
        language: str,
        message_text: str,
        chat_history: list = None,
        user_name: str = "",
        user_context: str = "",
        state_context: str = "",
    ) -> Dict[str, Any]:
        """Process a user message and return a response with structured data.

        Args:
            user_id: The user's ID
            phone_number: The user's WhatsApp phone number
            language: The user's preferred language
            message_text: The message text (already translated to French)
            chat_history: Optional chat history for context
            user_name: Official contact name from subcontractors table
            user_context: Additional user context for personalization
            state_context: AUTHORITATIVE explicit state (active project/task IDs)

        Returns:
            Dict with:
                - message: Response text (in French)
                - escalation: Whether escalation occurred
                - tools_called: List of tool names that were executed
                - tool_outputs: Structured tool outputs (for short-term memory)
        """
        # Use execution context scope for thread-safe execution tracking
        with execution_context_scope() as ctx:
            try:
                # Build agent with user-specific tools (closure pattern)
                # Tools capture user_id, phone_number, language from closure scope
                log.debug(f"üî® Building agent for user {user_id[:8]}...")
                agent_executor = create_agent(user_id, phone_number, language)

                # Build context prefix with AUTHORITATIVE state first
                # NOTE: Language code is intentionally NOT included here to ensure
                # agent always responds in French (internal processing language).
                # Translation to user language happens in the pipeline after agent response.
                # NOTE: user_id, phone_number, language are NO LONGER in text context
                # because they're captured in tool closures.
                context_prefix = ""

                # LAYER 1: Explicit State (AUTHORITATIVE - takes precedence)
                if state_context:
                    context_prefix += state_context  # Already formatted with headers

                # LAYER 2: User context (name only - NO user_id)
                context_prefix += "[Contexte utilisateur]\n"
                if user_name:
                    context_prefix += f"Nom: {user_name}\n"
                if user_context:
                    context_prefix += f"Contexte additionnel:\n{user_context}\n"
                context_prefix += "\n"

                # Prepare agent input (SIMPLIFIED - no user_id/phone/language in dict)
                # These are captured in tool closures, not passed to LLM
                agent_input: Dict[str, Any] = {
                    "input": f"{context_prefix}{message_text}",
                }

                if chat_history:
                    agent_input["chat_history"] = chat_history

                # Run agent
                log.debug(f"ü§ñ Invoking agent for user {user_id[:8]}...")
                result = await agent_executor.ainvoke(agent_input)

                # Extract output
                output = result.get(
                    "output", "D√©sol√©, je n'ai pas pu traiter votre demande."
                )

                # Normalize output to string (LangChain sometimes returns dict/list)
                if isinstance(output, dict):
                    # Extract 'text' field from dict: {'text': '...', 'type': 'text', 'index': 0}
                    log.warning("Agent returned dict output, extracting text field")
                    output = output.get("text", str(output))
                elif isinstance(output, list):
                    # List items might be dicts with 'text' field or plain strings
                    log.warning(
                        f"Agent returned list output ({len(output)} items), extracting text"
                    )
                    extracted_items = []
                    for item in output:
                        if isinstance(item, dict):
                            # Extract 'text' field from dict item
                            extracted_items.append(item.get("text", str(item)))
                        else:
                            # Plain string or other type
                            extracted_items.append(str(item))
                    output = "\n".join(extracted_items)
                elif not isinstance(output, str):
                    # Fallback: convert to string
                    log.warning(
                        f"Agent returned unexpected type {type(output)}, converting to string"
                    )
                    output = str(output)

                # Extract intermediate_steps (tool calls + outputs)
                # Format: List[Tuple[AgentAction, Any]]
                intermediate_steps = result.get("intermediate_steps", [])
                tool_outputs = []

                for action, tool_result in intermediate_steps:
                    # For list_tasks_tool, fetch structured data from action layer
                    # (tool_result is a formatted string, but we need structured data)
                    if action.tool == "list_tasks_tool":
                        # Re-fetch structured data from actions layer
                        from src.actions import tasks as task_actions
                        from src.utils.metadata_helpers import compact_tasks

                        project_id = action.tool_input.get("project_id")
                        user_id_input = action.tool_input.get("user_id")

                        if project_id and user_id_input:
                            task_result = await task_actions.list_tasks(
                                user_id_input, project_id
                            )
                            if task_result.get("success") and task_result.get("data"):
                                structured_output = compact_tasks(task_result["data"])
                                log.info(
                                    f"   üóúÔ∏è Stored structured data for list_tasks_tool: {len(structured_output)} tasks"
                                )
                            else:
                                structured_output = []
                        else:
                            structured_output = []

                        tool_output_entry = {
                            "tool": action.tool,
                            "input": action.tool_input,
                            "output": structured_output,  # Structured data, not string
                        }
                    else:
                        # For other tools, store as-is
                        tool_output_entry = {
                            "tool": action.tool,
                            "input": action.tool_input,
                            "output": tool_result,
                        }

                    tool_outputs.append(tool_output_entry)

                if tool_outputs:
                    log.info(
                        f"üì¶ Captured {len(tool_outputs)} tool outputs for short-term memory"
                    )

                # Get escalation flag from execution context (set by tools)
                escalation_occurred = ctx.escalation_occurred

                log.info(f"Agent processed message for user {user_id}")
                log.info(f"Escalation occurred: {escalation_occurred}")
                log.info(f"Tools called: {ctx.tools_called}")

                # Return structured data (output is guaranteed to be string now)
                return {
                    "message": output,
                    "escalation": escalation_occurred,
                    "tools_called": ctx.tools_called,
                    "tool_outputs": tool_outputs,  # NEW: Short-term tool memory
                }

            except Exception as e:
                log.error(f"Error processing message: {e}")
                return {
                    "message": "D√©sol√©, une erreur s'est produite. Veuillez r√©essayer.",
                    "escalation": False,
                    "tools_called": [],
                    "tool_outputs": [],
                }


# Global agent instance
lumiera_agent = LumieraAgent()
