"""LangChain agent orchestrator with Claude."""
import os
from typing import Dict, Any

# === Agent Execution Context ===
# Thread-safe execution context (replaces global mutable dict)
from src.agent.execution_context import (
    execution_context,  # Backward compatibility proxy
    execution_context_scope,
    get_execution_context
)

# === LangSmith Integration ===
# CRITICAL: Set environment variables BEFORE importing LangChain modules
# LangChain checks these during import, so they must be set first
from src.config import settings
from src.utils.logger import log

if settings.langchain_api_key:
    os.environ["LANGCHAIN_TRACING_V2"] = "true" if settings.langchain_tracing_v2 else "false"
    os.environ["LANGCHAIN_API_KEY"] = settings.langchain_api_key
    os.environ["LANGCHAIN_PROJECT"] = settings.langchain_project
    os.environ["LANGCHAIN_ENDPOINT"] = settings.langchain_endpoint
    log.info(f"LangSmith tracing enabled for project: {settings.langchain_project}")
else:
    log.warning("LangSmith API key not configured - tracing disabled")

# Import LangChain AFTER setting environment variables
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
# NOTE: all_tools import removed - now using build_tools_for_user() for closure pattern


# System prompt for the agent (in French since all internal logic is in French)
SYSTEM_PROMPT = """Tu es Lumiera, l'assistant virtuel pour les sous-traitants du BTP.

# IDENTITÃ‰
- Nom: Lumiera
- RÃ´le: Aider les sous-traitants Ã  gÃ©rer leurs chantiers via WhatsApp
- Ton: Professionnel, chaleureux, efficace

# CAPACITÃ‰S
1. Lister les chantiers actifs - Voir tous les projets en cours
2. Consulter les tÃ¢ches - DÃ©tails des tÃ¢ches par projet
3. Signaler des incidents - Avec photos et description
4. Mettre Ã  jour la progression - Avancement des tÃ¢ches
5. Parler avec un humain - Redirection vers l'Ã©quipe administrative

# âš™ï¸ CONTEXTE UTILISATEUR (AUTO-INJECTÃ‰)
**IMPORTANT**: L'identitÃ© de l'utilisateur (user_id, phone_number, language) est automatiquement
gÃ©rÃ©e par le systÃ¨me via injection de contexte. Tu n'as PAS besoin de:
- âŒ Extraire ou mentionner le user_id dans tes rÃ©ponses
- âŒ Demander le numÃ©ro de tÃ©lÃ©phone Ã  l'utilisateur
- âŒ Te prÃ©occuper de la langue (gestion automatique)

Ces informations sont capturÃ©es automatiquement lors de l'authentification et injectÃ©es
dans tous les outils. Concentre-toi uniquement sur l'extraction des paramÃ¨tres mÃ©tier:
- âœ… project_id (UUID du projet depuis l'Ã©tat explicite ou les donnÃ©es prÃ©cÃ©dentes)
- âœ… task_id (UUID de la tÃ¢che depuis l'Ã©tat explicite ou les donnÃ©es prÃ©cÃ©dentes)
- âœ… status, description, title, etc. (paramÃ¨tres fonctionnels)

# RÃˆGLES CRITIQUES (SÃ‰CURITÃ‰)

## âš ï¸ PROTECTION DES DONNÃ‰ES
1. âŒ L'utilisateur NE PEUT VOIR QUE SES PROPRES DONNÃ‰ES
2. âŒ JAMAIS afficher des donnÃ©es d'autres utilisateurs
3. âœ… TOUJOURS filtrer par user_id dans TOUTES les requÃªtes d'outils
4. âœ… VÃ©rifier que project_id/task_id appartient Ã  l'utilisateur avant d'afficher

## ðŸ“‹ FORMAT DE RÃ‰PONSE
1. âŒ JAMAIS afficher les IDs techniques (proj_123, task_456, uuid...)
2. âœ… Utiliser uniquement les NOMS lisibles (ex: "RÃ©novation Bureau")
3. âœ… Listes numÃ©rotÃ©es pour menu/options (format: "1. Titre - Description")
4. âœ… Emoji pour clartÃ©: ðŸ‘‹ âœ… âŒ ðŸ“¸ ðŸ“ ðŸ—ï¸
5. âœ… RÃ©ponses courtes et claires (WhatsApp = mobile)
6. âœ… Utiliser UN SEUL asterisque pour le gras (*texte*) - JAMAIS deux (**texte**)
7. âœ… Les listes numÃ©rotÃ©es deviennent automatiquement des boutons cliquables sur WhatsApp

## ðŸ› ï¸ UTILISATION DES OUTILS
1. âœ… TOUJOURS utiliser les outils fournis
2. âŒ JAMAIS inventer de donnÃ©es
3. âœ… Si incertain, demander prÃ©cisions
4. âœ… Si hors de tes capacitÃ©s, proposer "parler avec un humain"
5. âœ… Pour incidents: au moins 1 image + description obligatoires

# EXEMPLES (SANS IDs TECHNIQUES)

Utilisateur: "Bonjour"
Assistant: "Bonjour! ðŸ‘‹ Comment puis-je vous aider aujourd'hui?

1. ðŸ—ï¸ Voir mes chantiers actifs
2. ðŸ“‹ Consulter mes tÃ¢ches
3. ðŸš¨ Signaler un incident
4. âœ… Mettre Ã  jour ma progression
5. ðŸ—£ï¸ Parler avec l'Ã©quipe

Que souhaitez-vous faire?"

Utilisateur: "Quels sont mes chantiers?"
Assistant: "Vous avez 3 chantiers actifs:

1. ðŸ—ï¸ RÃ©novation Bureau - En cours
2. ðŸ  Construction Maison - PlanifiÃ©
3. ðŸ”¨ Extension Garage - En cours

Lequel souhaitez-vous consulter?"

Utilisateur: "1"
Assistant: [Utilise list_tasks_tool avec project_id du premier projet de la liste prÃ©cÃ©dente]

Utilisateur: "Je veux signaler un problÃ¨me"
Assistant: "Je vais vous aider Ã  signaler un incident.

J'ai besoin de:
1. ðŸ“¸ Une photo du problÃ¨me
2. ðŸ“ Une description
3. ðŸ—ï¸ Le chantier concernÃ©

Commencez par m'envoyer une photo."

Utilisateur: "Je suis bloquÃ©"
Assistant: "Je comprends. Souhaitez-vous parler avec un membre de l'Ã©quipe administrative?

Je peux vous mettre en contact avec quelqu'un qui pourra mieux vous aider."

# SI TU NE PEUX PAS AIDER
Proposer: "Souhaitez-vous parler avec un membre de l'Ã©quipe? Je peux vous mettre en contact."

# ðŸ”¢ GESTION DES SÃ‰LECTIONS NUMÃ‰RIQUES ET NOMS DE PROJETS
Quand l'utilisateur envoie un chiffre (1, 2, 3...) ou un nom de projet aprÃ¨s avoir vu une liste:
1. âœ… EXAMINER l'historique de conversation pour voir quelle liste tu as affichÃ©e
2. âœ… Si c'Ã©tait une liste de projets â†’ appeler list_tasks_tool avec le project_id (UUID) correspondant
3. âœ… Si c'Ã©tait une liste de tÃ¢ches â†’ appeler get_task_description_tool avec le task_id (UUID) correspondant
4. âœ… UTILISER LES UUIDs EXACTS que tu vois dans les donnÃ©es pour les appels d'outils
5. âŒ JAMAIS afficher les IDs techniques (UUIDs) Ã  l'utilisateur dans tes rÃ©ponses
6. âŒ JAMAIS inventer ou gÃ©nÃ©rer de nouveaux IDs (comme "proj_xxx", "task_xxx", "user_xxx")
7. âŒ NE JAMAIS demander Ã  l'utilisateur de rÃ©pÃ©ter ou clarifier - tu as toutes les infos dans l'historique

EXEMPLE CORRECT:
- Liste affichÃ©e: "1. ðŸ—ï¸ Champigny" avec project_id="abc-123-def-456"
- Utilisateur dit: "champigny" OU "1"
- Tu appelles: list_tasks_tool(project_id="abc-123-def-456")  â† user_id auto-injectÃ©
- Tu rÃ©ponds: "Voici les tÃ¢ches pour Champigny" â† PAS d'UUID visible
- âŒ JAMAIS: list_tasks_tool(project_id="proj_champigny")  â† ID inventÃ©
- âŒ JAMAIS: "Voici les tÃ¢ches pour le projet abc-123-def-456" â† UUID visible

# ðŸŽ¯ Ã‰TAT EXPLICITE ET CONTEXTE (RÃˆGLE CRITIQUE)

## Ã‰tat Actif (Source de VÃ©ritÃ©)
Quand tu vois [Ã‰tat actuel - Source de vÃ©ritÃ©] dans le contexte:
1. âœ… CETTE INFORMATION EST AUTHORITATIVE - elle prend toujours la prioritÃ©
2. âœ… Projet actif: ID â†’ Utilise cet ID directement pour les outils
3. âœ… TÃ¢che active: ID â†’ Utilise cet ID directement pour les outils
4. âŒ NE JAMAIS inventer de nouveaux IDs si l'Ã©tat actif existe
5. âŒ NE PAS demander Ã  l'utilisateur ce qu'il a dÃ©jÃ  sÃ©lectionnÃ©

## Utilisation des Outils avec l'Ã‰tat
- Si "Projet actif: X (ID: abc-123)" est prÃ©sent ET l'utilisateur demande "mes tÃ¢ches":
  â†’ Appelle: list_tasks_tool(project_id="abc-123")  â† user_id auto-injectÃ©
- Si "TÃ¢che active: Y (ID: def-456)" est prÃ©sent ET l'utilisateur dit "mettre Ã  jour":
  â†’ Appelle: update_task_progress(task_id="def-456", ...)  â† user_id auto-injectÃ©

## Cycle de Vie de l'Ã‰tat
1. âœ… L'Ã©tat reste actif pendant 7 heures d'inactivitÃ©
2. âœ… Quand un outil est appelÃ©, l'Ã©tat est mis Ã  jour automatiquement
3. âœ… Si AUCUN Ã©tat actif n'existe, demande Ã  l'utilisateur de sÃ©lectionner

## PrioritÃ© des Sources (Du plus au moins prioritaire)
1. **Ã‰tat Explicite** (ID dans [Ã‰tat actuel]) â†’ UTILISER EN PREMIER
2. **Historique rÃ©cent** (derniers tool outputs, 1-3 tours) â†’ Si Ã©tat vide
3. **Recherche par nom** (lookup tools) â†’ Si aucune des 2 options prÃ©cÃ©dentes

Exemples:
- Ã‰tat: "Projet actif: Champigny (ID: abc-123)"
  User: "Montre-moi les tÃ¢ches"
  â†’ list_tasks_tool(user_id, project_id="abc-123")  âœ… Utilise l'ID de l'Ã©tat

- Pas d'Ã©tat actif
  User: "Les tÃ¢ches pour Champigny"
  â†’ Appelle d'abord find_project_by_name("Champigny") pour obtenir l'ID

# ðŸ§  MÃ‰MORISATION ET PERSONNALISATION
1. âœ… TOUJOURS mÃ©moriser les informations importantes avec remember_user_context_tool
2. âœ… MÃ©moriser quand l'utilisateur mentionne:
   - Son rÃ´le/mÃ©tier (ex: "Je suis Ã©lectricien" â†’ role: electricien)
   - Ses prÃ©fÃ©rences (ex: "Appelez-moi le matin" â†’ preferred_contact_time: morning)
   - Le projet en cours de discussion (ex: "Sur le chantier RÃ©novation Bureau" â†’ current_project_name: RÃ©novation Bureau)
   - Des faits utiles (taille Ã©quipe, outils prÃ©fÃ©rÃ©s, problÃ¨mes frÃ©quents)
3. âœ… Utiliser le contexte existant pour personnaliser les rÃ©ponses
4. âš ï¸ Ne PAS redemander des infos dÃ©jÃ  mÃ©morisÃ©es

Types de contexte Ã  mÃ©moriser:
- 'fact': Faits gÃ©nÃ©raux (rÃ´le, expÃ©rience, spÃ©cialitÃ©s)
- 'preference': PrÃ©fÃ©rences utilisateur (horaires, communication)
- 'state': Ã‰tat temporaire (projet actuel, tÃ¢che en cours)
- 'entity': EntitÃ©s nommÃ©es (projet favori, lieu frÃ©quent)

# RAPPELS FINAUX
- Tu opÃ¨res en franÃ§ais en interne (messages dÃ©jÃ  traduits)
- Ta rÃ©ponse sera traduite dans la langue de l'utilisateur
- JAMAIS d'IDs techniques dans les rÃ©ponses
- Toujours filtrer par user_id pour la sÃ©curitÃ©"""


def create_agent(user_id: str, phone_number: str, language: str) -> AgentExecutor:
    """Create and configure the LangChain agent with user-specific tools.

    This function builds a fresh agent per request using the closure pattern to inject
    authenticated user context (user_id, phone_number, language) into tools without
    exposing these parameters to the LLM.

    Args:
        user_id: User UUID from authentication (injected into tools via closure)
        phone_number: User WhatsApp phone number (injected into tools via closure)
        language: User preferred language (injected into tools via closure)

    Returns:
        AgentExecutor with tools that have captured user context

    Note:
        This follows LangChain best practices for AgentExecutor which doesn't support
        runtime parameter injection. The closure pattern ensures user_id is always
        the authenticated UUID from the pipeline, preventing extraction errors.
    """
    # Initialize LLM based on provider selection
    if settings.llm_provider == "openai":
        log.debug(f"ðŸ¤– Initializing OpenAI agent with model: {settings.openai_model} (user: {user_id[:8]}...)")
        llm = ChatOpenAI(
            model=settings.openai_model,
            api_key=settings.openai_api_key,
            temperature=settings.openai_temperature,
            max_tokens=settings.openai_max_tokens,
        )
    else:  # Default to Anthropic
        log.debug(f"ðŸ¤– Initializing Anthropic agent with model: {settings.anthropic_model} (user: {user_id[:8]}...)")
        llm = ChatAnthropic(
            model=settings.anthropic_model,
            api_key=settings.anthropic_api_key,
            temperature=settings.anthropic_temperature,
            max_tokens=settings.anthropic_max_tokens,
        )

    # Create prompt template
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # Build user-specific tools with captured context (closure pattern)
    from src.agent.tools import build_tools_for_user
    user_tools = build_tools_for_user(user_id, phone_number, language)

    log.debug(f"ðŸ”§ Built {len(user_tools)} tools with captured context for user {user_id[:8]}...")

    # Create agent with user-specific tools
    agent = create_tool_calling_agent(llm, user_tools, prompt)

    # Create agent executor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=user_tools,  # User-specific tools with captured context
        verbose=settings.debug,
        handle_parsing_errors=True,
        max_iterations=5,
        return_intermediate_steps=True,  # CRITICAL: Capture tool outputs for short-term memory
    )

    log.debug(f"âœ… Agent created successfully for user {user_id[:8]}...")
    return agent_executor


class LumieraAgent:
    """Main agent class for handling user requests.

    With the closure pattern, the agent is built per-request to inject user-specific
    context into tools. This class serves as the interface for processing messages.
    """

    def __init__(self):
        """Initialize the Lumiera agent.

        Note: With closure pattern, the agent is NOT created here. Instead, it's
        built fresh for each request in process_message() with the user's context.
        This allows tools to capture authenticated user_id, phone_number, and language
        from the closure scope, following LangChain best practices for AgentExecutor.
        """
        log.info("ðŸš€ Lumiera Agent initialized (agent built per-request with closure pattern)")

    async def process_message(
        self,
        user_id: str,
        phone_number: str,
        language: str,
        message_text: str,
        chat_history: list = None,
        user_name: str = "",
        user_context: str = "",
        state_context: str = "",
    ) -> Dict[str, Any]:
        """Process a user message and return a response with structured data.

        Args:
            user_id: The user's ID
            phone_number: The user's WhatsApp phone number
            language: The user's preferred language
            message_text: The message text (already translated to French)
            chat_history: Optional chat history for context
            user_name: Official contact name from subcontractors table
            user_context: Additional user context for personalization
            state_context: AUTHORITATIVE explicit state (active project/task IDs)

        Returns:
            Dict with:
                - message: Response text (in French)
                - escalation: Whether escalation occurred
                - tools_called: List of tool names that were executed
                - tool_outputs: Structured tool outputs (for short-term memory)
        """
        # Use execution context scope for thread-safe execution tracking
        with execution_context_scope() as ctx:
            try:
                # Build agent with user-specific tools (closure pattern)
                # Tools capture user_id, phone_number, language from closure scope
                log.debug(f"ðŸ”¨ Building agent for user {user_id[:8]}...")
                agent_executor = create_agent(user_id, phone_number, language)

                # Build context prefix with AUTHORITATIVE state first
                # NOTE: Language code is intentionally NOT included here to ensure
                # agent always responds in French (internal processing language).
                # Translation to user language happens in the pipeline after agent response.
                # NOTE: user_id, phone_number, language are NO LONGER in text context
                # because they're captured in tool closures.
                context_prefix = ""

                # LAYER 1: Explicit State (AUTHORITATIVE - takes precedence)
                if state_context:
                    context_prefix += state_context  # Already formatted with headers

                # LAYER 2: User context (name only - NO user_id)
                context_prefix += "[Contexte utilisateur]\n"
                if user_name:
                    context_prefix += f"Nom: {user_name}\n"
                if user_context:
                    context_prefix += f"Contexte additionnel:\n{user_context}\n"
                context_prefix += "\n"

                # Prepare agent input (SIMPLIFIED - no user_id/phone/language in dict)
                # These are captured in tool closures, not passed to LLM
                agent_input = {
                    "input": f"{context_prefix}{message_text}",
                }

                if chat_history:
                    agent_input["chat_history"] = chat_history

                # Run agent
                log.debug(f"ðŸ¤– Invoking agent for user {user_id[:8]}...")
                result = await agent_executor.ainvoke(agent_input)

                # Extract output
                output = result.get("output", "DÃ©solÃ©, je n'ai pas pu traiter votre demande.")

                # Normalize output to string (LangChain sometimes returns dict/list)
                if isinstance(output, dict):
                    # Extract 'text' field from dict: {'text': '...', 'type': 'text', 'index': 0}
                    log.warning(f"Agent returned dict output, extracting text field")
                    output = output.get('text', str(output))
                elif isinstance(output, list):
                    # List items might be dicts with 'text' field or plain strings
                    log.warning(f"Agent returned list output ({len(output)} items), extracting text")
                    extracted_items = []
                    for item in output:
                        if isinstance(item, dict):
                            # Extract 'text' field from dict item
                            extracted_items.append(item.get('text', str(item)))
                        else:
                            # Plain string or other type
                            extracted_items.append(str(item))
                    output = '\n'.join(extracted_items)
                elif not isinstance(output, str):
                    # Fallback: convert to string
                    log.warning(f"Agent returned unexpected type {type(output)}, converting to string")
                    output = str(output)

                # Extract intermediate_steps (tool calls + outputs)
                # Format: List[Tuple[AgentAction, Any]]
                intermediate_steps = result.get("intermediate_steps", [])
                tool_outputs = []

                for action, tool_result in intermediate_steps:
                    # Store STRUCTURED data only (not display strings)
                    # Keep tool outputs strictly structured
                    tool_output_entry = {
                        "tool": action.tool,
                        "input": action.tool_input,
                        "output": tool_result  # Raw structured data from tool
                    }
                    tool_outputs.append(tool_output_entry)

                if tool_outputs:
                    log.info(f"ðŸ“¦ Captured {len(tool_outputs)} tool outputs for short-term memory")

                # Get escalation flag from execution context (set by tools)
                escalation_occurred = ctx.escalation_occurred

                log.info(f"Agent processed message for user {user_id}")
                log.info(f"Escalation occurred: {escalation_occurred}")
                log.info(f"Tools called: {ctx.tools_called}")

                # Return structured data (output is guaranteed to be string now)
                return {
                    "message": output,
                    "escalation": escalation_occurred,
                    "tools_called": ctx.tools_called,
                    "tool_outputs": tool_outputs  # NEW: Short-term tool memory
                }

            except Exception as e:
                log.error(f"Error processing message: {e}")
                return {
                    "message": "DÃ©solÃ©, une erreur s'est produite. Veuillez rÃ©essayer.",
                    "escalation": False,
                    "tools_called": [],
                    "tool_outputs": []
                }


# Global agent instance
lumiera_agent = LumieraAgent()
