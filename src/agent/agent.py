"""LangChain agent orchestrator with Claude."""
import os
from typing import Dict, Any

# === Agent Execution Context ===
# Thread-safe execution context (replaces global mutable dict)
from src.agent.execution_context import (
    execution_context,  # Backward compatibility proxy
    execution_context_scope,
    get_execution_context
)

# === LangSmith Integration ===
# CRITICAL: Set environment variables BEFORE importing LangChain modules
# LangChain checks these during import, so they must be set first
from src.config import settings
from src.utils.logger import log

if settings.langchain_api_key:
    os.environ["LANGCHAIN_TRACING_V2"] = "true" if settings.langchain_tracing_v2 else "false"
    os.environ["LANGCHAIN_API_KEY"] = settings.langchain_api_key
    os.environ["LANGCHAIN_PROJECT"] = settings.langchain_project
    os.environ["LANGCHAIN_ENDPOINT"] = settings.langchain_endpoint
    log.info(f"LangSmith tracing enabled for project: {settings.langchain_project}")
else:
    log.warning("LangSmith API key not configured - tracing disabled")

# Import LangChain AFTER setting environment variables
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from src.agent.tools import all_tools


# System prompt for the agent (in French since all internal logic is in French)
SYSTEM_PROMPT = """Tu es Lumiera, l'assistant virtuel pour les sous-traitants du BTP.

# IDENTIT√â
- Nom: Lumiera
- R√¥le: Aider les sous-traitants √† g√©rer leurs chantiers via WhatsApp
- Ton: Professionnel, chaleureux, efficace

# CAPACIT√âS
1. Lister les chantiers actifs - Voir tous les projets en cours
2. Consulter les t√¢ches - D√©tails des t√¢ches par projet
3. Signaler des incidents - Avec photos et description
4. Mettre √† jour la progression - Avancement des t√¢ches
5. Parler avec un humain - Redirection vers l'√©quipe administrative

# R√àGLES CRITIQUES (S√âCURIT√â)

## ‚ö†Ô∏è PROTECTION DES DONN√âES
1. ‚ùå L'utilisateur NE PEUT VOIR QUE SES PROPRES DONN√âES
2. ‚ùå JAMAIS afficher des donn√©es d'autres utilisateurs
3. ‚úÖ TOUJOURS filtrer par user_id dans TOUTES les requ√™tes d'outils
4. ‚úÖ V√©rifier que project_id/task_id appartient √† l'utilisateur avant d'afficher

## üìã FORMAT DE R√âPONSE
1. ‚ùå JAMAIS afficher les IDs techniques (proj_123, task_456, uuid...)
2. ‚úÖ Utiliser uniquement les NOMS lisibles (ex: "R√©novation Bureau")
3. ‚úÖ Listes num√©rot√©es pour menu/options (format: "1. Titre - Description")
4. ‚úÖ Emoji pour clart√©: üëã ‚úÖ ‚ùå üì∏ üìù üèóÔ∏è
5. ‚úÖ R√©ponses courtes et claires (WhatsApp = mobile)
6. ‚úÖ Utiliser UN SEUL asterisque pour le gras (*texte*) - JAMAIS deux (**texte**)
7. ‚úÖ Les listes num√©rot√©es deviennent automatiquement des boutons cliquables sur WhatsApp

## üõ†Ô∏è UTILISATION DES OUTILS
1. ‚úÖ TOUJOURS utiliser les outils fournis
2. ‚ùå JAMAIS inventer de donn√©es
3. ‚úÖ Si incertain, demander pr√©cisions
4. ‚úÖ Si hors de tes capacit√©s, proposer "parler avec un humain"
5. ‚úÖ Pour incidents: au moins 1 image + description obligatoires

# EXEMPLES (SANS IDs TECHNIQUES)

Utilisateur: "Bonjour"
Assistant: "Bonjour! üëã Comment puis-je vous aider aujourd'hui?

1. üèóÔ∏è Voir mes chantiers actifs
2. üìã Consulter mes t√¢ches
3. üö® Signaler un incident
4. ‚úÖ Mettre √† jour ma progression
5. üó£Ô∏è Parler avec l'√©quipe

Que souhaitez-vous faire?"

Utilisateur: "Quels sont mes chantiers?"
Assistant: "Vous avez 3 chantiers actifs:

1. üèóÔ∏è R√©novation Bureau - En cours
2. üè† Construction Maison - Planifi√©
3. üî® Extension Garage - En cours

Lequel souhaitez-vous consulter?"

Utilisateur: "1"
Assistant: [Utilise list_tasks_tool avec project_id du premier projet de la liste pr√©c√©dente]

Utilisateur: "Je veux signaler un probl√®me"
Assistant: "Je vais vous aider √† signaler un incident.

J'ai besoin de:
1. üì∏ Une photo du probl√®me
2. üìù Une description
3. üèóÔ∏è Le chantier concern√©

Commencez par m'envoyer une photo."

Utilisateur: "Je suis bloqu√©"
Assistant: "Je comprends. Souhaitez-vous parler avec un membre de l'√©quipe administrative?

Je peux vous mettre en contact avec quelqu'un qui pourra mieux vous aider."

# SI TU NE PEUX PAS AIDER
Proposer: "Souhaitez-vous parler avec un membre de l'√©quipe? Je peux vous mettre en contact."

# üî¢ GESTION DES S√âLECTIONS NUM√âRIQUES ET NOMS DE PROJETS
Quand l'utilisateur envoie un chiffre (1, 2, 3...) ou un nom de projet apr√®s avoir vu une liste:
1. ‚úÖ EXAMINER l'historique de conversation pour voir quelle liste tu as affich√©e
2. ‚úÖ Si c'√©tait une liste de projets ‚Üí appeler list_tasks_tool avec le project_id (UUID) correspondant
3. ‚úÖ Si c'√©tait une liste de t√¢ches ‚Üí appeler get_task_description_tool avec le task_id (UUID) correspondant
4. ‚úÖ UTILISER LES UUIDs EXACTS que tu vois dans les donn√©es pour les appels d'outils
5. ‚ùå JAMAIS afficher les IDs techniques (UUIDs) √† l'utilisateur dans tes r√©ponses
6. ‚ùå JAMAIS inventer ou g√©n√©rer de nouveaux IDs (comme "proj_xxx", "task_xxx", "user_xxx")
7. ‚ùå NE JAMAIS demander √† l'utilisateur de r√©p√©ter ou clarifier - tu as toutes les infos dans l'historique

EXEMPLE CORRECT:
- Liste affich√©e: "1. üèóÔ∏è Champigny" avec project_id="abc-123-def-456"
- Utilisateur dit: "champigny" OU "1"
- Tu appelles: list_tasks_tool(user_id="real-uuid", project_id="abc-123-def-456")
- Tu r√©ponds: "Voici les t√¢ches pour Champigny" ‚Üê PAS d'UUID visible
- ‚ùå JAMAIS: list_tasks_tool(user_id="user_jean", project_id="proj_champigny")
- ‚ùå JAMAIS: "Voici les t√¢ches pour le projet abc-123-def-456" ‚Üê UUID visible

# üéØ √âTAT EXPLICITE ET CONTEXTE (R√àGLE CRITIQUE)

## √âtat Actif (Source de V√©rit√©)
Quand tu vois [√âtat actuel - Source de v√©rit√©] dans le contexte:
1. ‚úÖ CETTE INFORMATION EST AUTHORITATIVE - elle prend toujours la priorit√©
2. ‚úÖ Projet actif: ID ‚Üí Utilise cet ID directement pour les outils
3. ‚úÖ T√¢che active: ID ‚Üí Utilise cet ID directement pour les outils
4. ‚ùå NE JAMAIS inventer de nouveaux IDs si l'√©tat actif existe
5. ‚ùå NE PAS demander √† l'utilisateur ce qu'il a d√©j√† s√©lectionn√©

## Utilisation des Outils avec l'√âtat
- Si "Projet actif: X (ID: abc-123)" est pr√©sent ET l'utilisateur demande "mes t√¢ches":
  ‚Üí Appelle: list_tasks_tool(user_id, project_id="abc-123")
- Si "T√¢che active: Y (ID: def-456)" est pr√©sent ET l'utilisateur dit "mettre √† jour":
  ‚Üí Appelle: update_task_progress(user_id, task_id="def-456", ...)

## Cycle de Vie de l'√âtat
1. ‚úÖ L'√©tat reste actif pendant 7 heures d'inactivit√©
2. ‚úÖ Quand un outil est appel√©, l'√©tat est mis √† jour automatiquement
3. ‚úÖ Si AUCUN √©tat actif n'existe, demande √† l'utilisateur de s√©lectionner

## Priorit√© des Sources (Du plus au moins prioritaire)
1. **√âtat Explicite** (ID dans [√âtat actuel]) ‚Üí UTILISER EN PREMIER
2. **Historique r√©cent** (derniers tool outputs, 1-3 tours) ‚Üí Si √©tat vide
3. **Recherche par nom** (lookup tools) ‚Üí Si aucune des 2 options pr√©c√©dentes

Exemples:
- √âtat: "Projet actif: Champigny (ID: abc-123)"
  User: "Montre-moi les t√¢ches"
  ‚Üí list_tasks_tool(user_id, project_id="abc-123")  ‚úÖ Utilise l'ID de l'√©tat

- Pas d'√©tat actif
  User: "Les t√¢ches pour Champigny"
  ‚Üí Appelle d'abord find_project_by_name("Champigny") pour obtenir l'ID

# üß† M√âMORISATION ET PERSONNALISATION
1. ‚úÖ TOUJOURS m√©moriser les informations importantes avec remember_user_context_tool
2. ‚úÖ M√©moriser quand l'utilisateur mentionne:
   - Son r√¥le/m√©tier (ex: "Je suis √©lectricien" ‚Üí role: electricien)
   - Ses pr√©f√©rences (ex: "Appelez-moi le matin" ‚Üí preferred_contact_time: morning)
   - Le projet en cours de discussion (ex: "Sur le chantier R√©novation Bureau" ‚Üí current_project_name: R√©novation Bureau)
   - Des faits utiles (taille √©quipe, outils pr√©f√©r√©s, probl√®mes fr√©quents)
3. ‚úÖ Utiliser le contexte existant pour personnaliser les r√©ponses
4. ‚ö†Ô∏è Ne PAS redemander des infos d√©j√† m√©moris√©es

Types de contexte √† m√©moriser:
- 'fact': Faits g√©n√©raux (r√¥le, exp√©rience, sp√©cialit√©s)
- 'preference': Pr√©f√©rences utilisateur (horaires, communication)
- 'state': √âtat temporaire (projet actuel, t√¢che en cours)
- 'entity': Entit√©s nomm√©es (projet favori, lieu fr√©quent)

# RAPPELS FINAUX
- Tu op√®res en fran√ßais en interne (messages d√©j√† traduits)
- Ta r√©ponse sera traduite dans la langue de l'utilisateur
- JAMAIS d'IDs techniques dans les r√©ponses
- Toujours filtrer par user_id pour la s√©curit√©"""


def create_agent() -> AgentExecutor:
    """Create and configure the LangChain agent with selected LLM provider."""

    # Initialize LLM based on provider selection
    if settings.llm_provider == "openai":
        log.info(f"ü§ñ Initializing OpenAI agent with model: {settings.openai_model}")
        llm = ChatOpenAI(
            model=settings.openai_model,
            api_key=settings.openai_api_key,
            temperature=settings.openai_temperature,
            max_tokens=settings.openai_max_tokens,
        )
    else:  # Default to Anthropic
        log.info(f"ü§ñ Initializing Anthropic agent with model: {settings.anthropic_model}")
        llm = ChatAnthropic(
            model=settings.anthropic_model,
            api_key=settings.anthropic_api_key,
            temperature=settings.anthropic_temperature,
            max_tokens=settings.anthropic_max_tokens,
        )

    # Create prompt template
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # Create agent with tool calling
    agent = create_tool_calling_agent(llm, all_tools, prompt)

    # Create agent executor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=all_tools,
        verbose=settings.debug,
        handle_parsing_errors=True,
        max_iterations=5,
        return_intermediate_steps=True,  # CRITICAL: Capture tool outputs for short-term memory
    )

    log.info("Agent created successfully")
    return agent_executor


class LumieraAgent:
    """Main agent class for handling user requests."""

    def __init__(self):
        """Initialize the Lumiera agent."""
        self.agent_executor = create_agent()
        log.info("Lumiera Agent initialized")

    async def process_message(
        self,
        user_id: str,
        phone_number: str,
        language: str,
        message_text: str,
        chat_history: list = None,
        user_name: str = "",
        user_context: str = "",
        state_context: str = "",
    ) -> Dict[str, Any]:
        """Process a user message and return a response with structured data.

        Args:
            user_id: The user's ID
            phone_number: The user's WhatsApp phone number
            language: The user's preferred language
            message_text: The message text (already translated to French)
            chat_history: Optional chat history for context
            user_name: Official contact name from subcontractors table
            user_context: Additional user context for personalization
            state_context: AUTHORITATIVE explicit state (active project/task IDs)

        Returns:
            Dict with:
                - message: Response text (in French)
                - escalation: Whether escalation occurred
                - tools_called: List of tool names that were executed
                - tool_outputs: Structured tool outputs (for short-term memory)
        """
        # Use execution context scope for thread-safe execution tracking
        with execution_context_scope() as ctx:
            try:
                # Build context prefix with AUTHORITATIVE state first
                # NOTE: Language code is intentionally NOT included here to ensure
                # agent always responds in French (internal processing language).
                # Translation to user language happens in the pipeline after agent response.
                context_prefix = ""

                # LAYER 1: Explicit State (AUTHORITATIVE - takes precedence)
                if state_context:
                    context_prefix += state_context  # Already formatted with headers

                # LAYER 2: User context
                context_prefix += "[Contexte utilisateur]\n"
                if user_name:
                    context_prefix += f"Nom: {user_name}\n"
                if user_context:
                    context_prefix += f"Contexte additionnel:\n{user_context}\n"
                context_prefix += "\n"

                # Prepare agent input
                agent_input = {
                    "input": f"{context_prefix}{message_text}",
                    "user_id": user_id,
                    "phone_number": phone_number,
                    "language": language,
                }

                if chat_history:
                    agent_input["chat_history"] = chat_history

                # Run agent
                result = await self.agent_executor.ainvoke(agent_input)

                # Extract output
                output = result.get("output", "D√©sol√©, je n'ai pas pu traiter votre demande.")

                # Normalize output to string (LangChain sometimes returns dict/list)
                if isinstance(output, dict):
                    # Extract 'text' field from dict: {'text': '...', 'type': 'text', 'index': 0}
                    log.warning(f"Agent returned dict output, extracting text field")
                    output = output.get('text', str(output))
                elif isinstance(output, list):
                    # List items might be dicts with 'text' field or plain strings
                    log.warning(f"Agent returned list output ({len(output)} items), extracting text")
                    extracted_items = []
                    for item in output:
                        if isinstance(item, dict):
                            # Extract 'text' field from dict item
                            extracted_items.append(item.get('text', str(item)))
                        else:
                            # Plain string or other type
                            extracted_items.append(str(item))
                    output = '\n'.join(extracted_items)
                elif not isinstance(output, str):
                    # Fallback: convert to string
                    log.warning(f"Agent returned unexpected type {type(output)}, converting to string")
                    output = str(output)

                # Extract intermediate_steps (tool calls + outputs)
                # Format: List[Tuple[AgentAction, Any]]
                intermediate_steps = result.get("intermediate_steps", [])
                tool_outputs = []

                for action, tool_result in intermediate_steps:
                    # Store STRUCTURED data only (not display strings)
                    # Keep tool outputs strictly structured
                    tool_output_entry = {
                        "tool": action.tool,
                        "input": action.tool_input,
                        "output": tool_result  # Raw structured data from tool
                    }
                    tool_outputs.append(tool_output_entry)

                if tool_outputs:
                    log.info(f"üì¶ Captured {len(tool_outputs)} tool outputs for short-term memory")

                # Get escalation flag from execution context (set by tools)
                escalation_occurred = ctx.escalation_occurred

                log.info(f"Agent processed message for user {user_id}")
                log.info(f"Escalation occurred: {escalation_occurred}")
                log.info(f"Tools called: {ctx.tools_called}")

                # Return structured data (output is guaranteed to be string now)
                return {
                    "message": output,
                    "escalation": escalation_occurred,
                    "tools_called": ctx.tools_called,
                    "tool_outputs": tool_outputs  # NEW: Short-term tool memory
                }

            except Exception as e:
                log.error(f"Error processing message: {e}")
                return {
                    "message": "D√©sol√©, une erreur s'est produite. Veuillez r√©essayer.",
                    "escalation": False,
                    "tools_called": [],
                    "tool_outputs": []
                }


# Global agent instance
lumiera_agent = LumieraAgent()
